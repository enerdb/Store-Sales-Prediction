{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "155ff54f",
   "metadata": {},
   "source": [
    "# DESCRIÇÃO DO NEGÓCIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd866ea",
   "metadata": {},
   "source": [
    "Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied.\n",
    "\n",
    "Submissions are evaluated on the Root Mean Square Percentage Error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db1f742",
   "metadata": {},
   "source": [
    "## Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd6540e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:31.863485Z",
     "start_time": "2021-10-29T16:52:31.849522Z"
    }
   },
   "outputs": [],
   "source": [
    "show_graphics = False\n",
    "\n",
    "run_boruta = False\n",
    "\n",
    "fine_tunning = False\n",
    "\n",
    "# store_fraction reduces the number of stores to train n times\n",
    "store_fraction = 17\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fb7ec3",
   "metadata": {},
   "source": [
    "# 0.0 IMPORTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebffa6e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.380153Z",
     "start_time": "2021-10-29T16:52:31.864482Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display       import Image\n",
    "from IPython.core.display  import HTML\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import inflection # biblioteca para padronizar o nome das variaveis\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "\n",
    "from matplotlib            import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "if(run_boruta):\n",
    "    from boruta import BorutaPy\n",
    "\n",
    "warnings.filterwarnings( 'ignore' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13617b5f",
   "metadata": {},
   "source": [
    "## 0.1 Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79fdf8d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.383145Z",
     "start_time": "2021-10-29T16:52:34.383145Z"
    }
   },
   "outputs": [],
   "source": [
    "def cramer_v(x, y):\n",
    "    cm = pd.crosstab( x, y).values\n",
    "    chi2 = ss.chi2_contingency( cm )[0]\n",
    "    n = cm.sum()\n",
    "    r,k = cm.shape\n",
    "    \n",
    "    chi2corr = max(0, chi2 -(k-1)*(r-1)/(n-1))\n",
    "    kcorr = k - (k-1)**2/(n-1)\n",
    "    rcorr = r - (r-1)**2/(n-1)\n",
    "        \n",
    "    return np.sqrt( (chi2corr/n) / (min(kcorr-1,rcorr-1) ) )\n",
    "\n",
    "def mean_percentage_error( y, yhat ):\n",
    "    return np.mean( ( y - yhat ) / y )\n",
    "     \n",
    "    \n",
    "def mean_absolute_percentage_error( y, yhat ):\n",
    "    return np.mean( np.abs( ( y - yhat ) / y ) )\n",
    "\n",
    "    \n",
    "def ml_error( model_name, y, yhat ):\n",
    "    mae = mean_absolute_error( y, yhat )\n",
    "    mape = mean_absolute_percentage_error( y, yhat )\n",
    "    rmse = np.sqrt( mean_squared_error( y, yhat ) )\n",
    "    \n",
    "    return pd.DataFrame( { 'Model Name': model_name, \n",
    "                           'MAE': mae, \n",
    "                           'MAPE': mape,\n",
    "                           'RMSE': rmse }, index=[0] )\n",
    "\n",
    "def cross_validation( X, kfold, model_name, model, verbose=False ):\n",
    "    mae_list = []\n",
    "    mape_list = []\n",
    "    rmse_list = []\n",
    "    for k in reversed( range( 1, kfold+1 ) ):\n",
    "        if verbose:\n",
    "            print( '\\nKFold Number: {}'.format( k ) )\n",
    "            \n",
    "        # start and end date for validation \n",
    "        validation_start_date = X['date'].max() - datetime.timedelta( days=k*6*7)\n",
    "        validation_end_date = X['date'].max() - datetime.timedelta( days=(k-1)*6*7)\n",
    "\n",
    "        # Subsetting dates\n",
    "        X_train = X[X['date'] < validation_start_date]\n",
    "        X_validation = X[(X['date'] >= validation_start_date) & (X['date'] <= validation_end_date)]\n",
    "\n",
    "        # training and validation dataset\n",
    "        # training\n",
    "        y_train = X_train['sales']\n",
    "        X_train = X_train.drop( ['date', 'sales'], axis=1 ) \n",
    "        \n",
    "\n",
    "        # validation\n",
    "        y_validation = X_validation['sales']\n",
    "        X_validation = X_validation.drop( ['date', 'sales'], axis=1 )\n",
    "        \n",
    "        # model\n",
    "        model.fit( X_train, y_train )\n",
    "\n",
    "        # prediction\n",
    "        yhat = model.predict( X_validation )\n",
    "\n",
    "        # performance\n",
    "        m_result = ml_error( model_name, np.expm1( y_validation ), np.expm1( yhat ) )\n",
    "\n",
    "        # store performance of each kfold iteration\n",
    "        mae_list.append(  m_result['MAE'] )\n",
    "        mape_list.append( m_result['MAPE'] )\n",
    "        rmse_list.append( m_result['RMSE'] )\n",
    "\n",
    "    return pd.DataFrame( {'Model Name': model_name,\n",
    "                          'MAE CV': np.round( np.mean( mae_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mae_list ), 2 ).astype( str ),\n",
    "                          'MAPE CV': np.round( np.mean( mape_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mape_list ), 2 ).astype( str ),\n",
    "                          'RMSE CV': np.round( np.mean( rmse_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( rmse_list ), 2 ).astype( str ) }, index=[0] )\n",
    "\n",
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    %pylab inline\n",
    "    \n",
    "    plt.style.use( 'bmh' )\n",
    "    plt.rcParams['figure.figsize'] = [25, 12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    \n",
    "    display( HTML( '<style>.container { width:100% !important; }</style>') )\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option( 'display.expand_frame_repr', False )\n",
    "    \n",
    "    sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fc8067d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.387134Z",
     "start_time": "2021-10-29T16:52:34.387134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5fb087",
   "metadata": {},
   "source": [
    "## 0.2 Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f43fe9be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.388131Z",
     "start_time": "2021-10-29T16:52:34.388131Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sales_raw = pd.read_csv(\"data/train.csv\", low_memory=False)\n",
    "df_store_raw = pd.read_csv(\"data/store.csv\", low_memory=False)\n",
    "\n",
    "# merge\n",
    "df_raw = pd.merge(df_sales_raw, df_store_raw, how='left', on='Store')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79857ca7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.388131Z",
     "start_time": "2021-10-29T16:52:34.388131Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>6064</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8314</td>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>13995</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>620.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>4822</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>29910.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  SchoolHoliday StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear    PromoInterval\n",
       "0      1          5  2015-07-31   5263        555     1      1            0              1         c          a               1270.0                        9.0                    2008.0       0              NaN              NaN              NaN\n",
       "1      2          5  2015-07-31   6064        625     1      1            0              1         a          a                570.0                       11.0                    2007.0       1             13.0           2010.0  Jan,Apr,Jul,Oct\n",
       "2      3          5  2015-07-31   8314        821     1      1            0              1         a          a              14130.0                       12.0                    2006.0       1             14.0           2011.0  Jan,Apr,Jul,Oct\n",
       "3      4          5  2015-07-31  13995       1498     1      1            0              1         c          c                620.0                        9.0                    2009.0       0              NaN              NaN              NaN\n",
       "4      5          5  2015-07-31   4822        559     1      1            0              1         a          a              29910.0                        4.0                    2015.0       0              NaN              NaN              NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f88c3",
   "metadata": {},
   "source": [
    "# 1.0 DATA DESCRIPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc26100",
   "metadata": {},
   "source": [
    "Data fields\n",
    "Most of the fields are self-explanatory. The following are descriptions for those that aren't.\n",
    "\n",
    "* Id - an Id that represents a (Store, Date) duple within the test set\n",
    "* Store - a unique Id for each store\n",
    "* Sales - the turnover for any given day (this is what you are predicting)\n",
    "* Customers - the number of customers on a given day\n",
    "* Open - an indicator for whether the store was open: 0 = closed, 1 = open\n",
    "* StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None\n",
    "* SchoolHoliday - indicates if the (Store, Date) was affected by the closure of public schools\n",
    "* StoreType - differentiates between 4 different store models: a, b, c, d\n",
    "* Assortment - describes an assortment level: a = basic, b = extra, c = extended\n",
    "* CompetitionDistance - distance in meters to the nearest competitor store\n",
    "* CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened\n",
    "* Promo - indicates whether a store is running a promo on that day\n",
    "* Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating\n",
    "* Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2\n",
    "* PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c96afffc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.390128Z",
     "start_time": "2021-10-29T16:52:34.390128Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df_raw[df_raw['Store'] % store_fraction ==0].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066d7013",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 1.1 Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f72649f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.391123Z",
     "start_time": "2021-10-29T16:52:34.391123Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols_old = ['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo',\n",
    "       'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
    "       'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
    "       'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n",
    "       'Promo2SinceYear', 'PromoInterval']\n",
    "\n",
    "snakecase = lambda x: inflection.underscore(x)\n",
    "\n",
    "cols_new = list(map(snakecase, cols_old))\n",
    "\n",
    "# rename\n",
    "df1.columns = cols_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401562e4",
   "metadata": {},
   "source": [
    "## 1.2 Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66196601",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.392121Z",
     "start_time": "2021-10-29T16:52:34.392121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 59574\n",
      "Number of Cols: 18\n"
     ]
    }
   ],
   "source": [
    "print('Number of Rows: {}'.format(df1.shape[0]))\n",
    "print('Number of Cols: {}'.format(df1.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70fdf7f",
   "metadata": {},
   "source": [
    "## 1.3 Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89c66343",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.392121Z",
     "start_time": "2021-10-29T16:52:34.392121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store                             int64\n",
       "day_of_week                       int64\n",
       "date                             object\n",
       "sales                             int64\n",
       "customers                         int64\n",
       "open                              int64\n",
       "promo                             int64\n",
       "state_holiday                    object\n",
       "school_holiday                    int64\n",
       "store_type                       object\n",
       "assortment                       object\n",
       "competition_distance            float64\n",
       "competition_open_since_month    float64\n",
       "competition_open_since_year     float64\n",
       "promo2                            int64\n",
       "promo2_since_week               float64\n",
       "promo2_since_year               float64\n",
       "promo_interval                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55e282d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.393117Z",
     "start_time": "2021-10-29T16:52:34.393117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store                                    int64\n",
       "day_of_week                              int64\n",
       "date                            datetime64[ns]\n",
       "sales                                    int64\n",
       "customers                                int64\n",
       "open                                     int64\n",
       "promo                                    int64\n",
       "state_holiday                           object\n",
       "school_holiday                           int64\n",
       "store_type                              object\n",
       "assortment                              object\n",
       "competition_distance                   float64\n",
       "competition_open_since_month           float64\n",
       "competition_open_since_year            float64\n",
       "promo2                                   int64\n",
       "promo2_since_week                      float64\n",
       "promo2_since_year                      float64\n",
       "promo_interval                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['date'] = pd.to_datetime(df1['date'])\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46819448",
   "metadata": {},
   "source": [
    "## 1.4 Check NA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da6b14",
   "metadata": {},
   "source": [
    "Há 3 formas de substituir NAs\n",
    "* Drop NA rows\n",
    "* Using statistics and machine learning to infere data\n",
    "* Understanding why the data is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a8bc818",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.394115Z",
     "start_time": "2021-10-29T16:52:34.394115Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store                               0\n",
       "day_of_week                         0\n",
       "date                                0\n",
       "sales                               0\n",
       "customers                           0\n",
       "open                                0\n",
       "promo                               0\n",
       "state_holiday                       0\n",
       "school_holiday                      0\n",
       "store_type                          0\n",
       "assortment                          0\n",
       "competition_distance                0\n",
       "competition_open_since_month    16772\n",
       "competition_open_since_year     16772\n",
       "promo2                              0\n",
       "promo2_since_week               25824\n",
       "promo2_since_year               25824\n",
       "promo_interval                  25824\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3e6d02",
   "metadata": {},
   "source": [
    "## 1.5 Fillout NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b3e696d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.395113Z",
     "start_time": "2021-10-29T16:52:34.395113Z"
    }
   },
   "outputs": [],
   "source": [
    "#competition_distance              2642\n",
    "# Imaginar que não há competidores próximos, ou seja, distância grande.\n",
    "faraway = 100*df1.competition_distance.max()\n",
    "near = 50\n",
    "\n",
    "df1['competition_distance'].fillna(faraway, inplace=True)\n",
    "df1['competition_distance'] = df1['competition_distance'].apply(lambda x: near if x <=near else x)\n",
    "\n",
    "# A ideia aqui é aplicar o data atual (do dado lido) para dizer depois que não há tempo com concorrente.\n",
    "# applicar df1.date para os campos de competition open since\n",
    "\n",
    "#competition_open_since_month    323348\n",
    "df1['competition_open_since_month']= df1.apply(lambda x: x['date'].month if math.isnan(x['competition_open_since_month']) else x['competition_open_since_month'], axis=1)\n",
    "\n",
    "#competition_open_since_year     323348\n",
    "df1['competition_open_since_year']= df1.apply(lambda x: x['date'].year if math.isnan(x['competition_open_since_year']) else x['competition_open_since_year'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13d14c93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.397108Z",
     "start_time": "2021-10-29T16:52:34.397108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with promo2 == 0: 25824\n",
      "Number of rows with promo2 == 1 and missing since values: 0\n"
     ]
    }
   ],
   "source": [
    "# Para os dados de promo2_since_, fazer o mesmo. Aparentemente, não os dados faltantes são os que não há promo2,\n",
    "# checar na mão!\n",
    "\n",
    "print('Number of rows with promo2 == 0: {}'.format(df1[df1['promo2']== 0].shape[0]))\n",
    "print('Number of rows with promo2 == 1 and missing since values: {}'.format((df1[df1['promo2']== 1 & (df1['promo2_since_week'].isna() | df1['promo2_since_year'].isna())].shape[0])))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55fd805e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.399102Z",
     "start_time": "2021-10-29T16:52:34.399102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Atribuir a data atual (da leitura) para dizer que não há tempo desde a última promo.\n",
    "#promo2_since_week              508031\n",
    "\n",
    "df1['promo2_since_week'] = df1.apply(lambda x: x['date'].week if math.isnan(x['promo2_since_week']) else x['promo2_since_week'], axis=1)\n",
    "\n",
    "#promo2_since_year               508031\n",
    "df1['promo2_since_year'] = df1.apply(lambda x: x['date'].year if math.isnan(x['promo2_since_year']) else x['promo2_since_year'], axis=1)\n",
    "\n",
    "\n",
    "#promo_interval  \n",
    "\n",
    "# criar month map dict\n",
    "month_map = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "\n",
    "# criar colunas 'month_map' com base em date\n",
    "df1['month_map'] = df1['date'].dt.month.map(month_map)\n",
    "\n",
    "# criar 'is_promo' comparando o map com promo_inverval\n",
    "df1['promo_interval'].fillna('', inplace=True)\n",
    "\n",
    "\n",
    "df1['is_promo'] = df1[['promo_interval', 'month_map']].apply(lambda x: 1 if x['month_map'] in x['promo_interval'].split(',')\n",
    "                            else 0 ,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d616952f",
   "metadata": {},
   "source": [
    "## 1.6. Change Data Types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c92fb40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.400099Z",
     "start_time": "2021-10-29T16:52:34.400099Z"
    }
   },
   "outputs": [],
   "source": [
    "# competiton\n",
    "df1['competition_open_since_month'] = df1['competition_open_since_month'].astype( int64 )\n",
    "df1['competition_open_since_year'] = df1['competition_open_since_year'].astype( int64 )\n",
    "    \n",
    "# promo2\n",
    "df1['promo2_since_week'] = df1['promo2_since_week'].astype( int64 )\n",
    "df1['promo2_since_year'] = df1['promo2_since_year'].astype( int64 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de8b0c0",
   "metadata": {},
   "source": [
    "## 1.7. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ddb2463",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.402094Z",
     "start_time": "2021-10-29T16:52:34.401097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store                                    int64\n",
       "day_of_week                              int64\n",
       "date                            datetime64[ns]\n",
       "sales                                    int64\n",
       "customers                                int64\n",
       "open                                     int64\n",
       "promo                                    int64\n",
       "state_holiday                           object\n",
       "school_holiday                           int64\n",
       "store_type                              object\n",
       "assortment                              object\n",
       "competition_distance                   float64\n",
       "competition_open_since_month             int64\n",
       "competition_open_since_year              int64\n",
       "promo2                                   int64\n",
       "promo2_since_week                        int64\n",
       "promo2_since_year                        int64\n",
       "promo_interval                          object\n",
       "month_map                               object\n",
       "is_promo                                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7c4ddef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.403093Z",
     "start_time": "2021-10-29T16:52:34.403093Z"
    }
   },
   "outputs": [],
   "source": [
    "num_attributes = df1.select_dtypes( include=['int64', 'float64'] )\n",
    "cat_attributes = df1.select_dtypes( exclude=['int64', 'float64', 'datetime64[ns]'] )\n",
    "\n",
    "num_attributes_list = list(num_attributes.columns)\n",
    "cat_attributes_list = list(cat_attributes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd315f0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.404088Z",
     "start_time": "2021-10-29T16:52:34.404088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>sales</th>\n",
       "      <th>customers</th>\n",
       "      <th>open</th>\n",
       "      <th>promo</th>\n",
       "      <th>school_holiday</th>\n",
       "      <th>competition_distance</th>\n",
       "      <th>competition_open_since_month</th>\n",
       "      <th>competition_open_since_year</th>\n",
       "      <th>promo2</th>\n",
       "      <th>promo2_since_week</th>\n",
       "      <th>promo2_since_year</th>\n",
       "      <th>is_promo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>8430</td>\n",
       "      <td>946</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>11144</td>\n",
       "      <td>1162</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>9198</td>\n",
       "      <td>610</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10570.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>11187</td>\n",
       "      <td>1341</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>250.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "      <td>7791</td>\n",
       "      <td>971</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    store  day_of_week  sales  customers  open  promo  school_holiday  competition_distance  competition_open_since_month  competition_open_since_year  promo2  promo2_since_week  promo2_since_year  is_promo\n",
       "16     17            5   8430        946     1      1               1                  50.0                            12                         2005       1                 26               2010         1\n",
       "33     34            5  11144       1162     1      1               1                2240.0                             9                         2009       0                 31               2015         0\n",
       "50     51            5   9198        610     1      1               0               10570.0                             7                         2013       1                  9               2011         1\n",
       "67     68            5  11187       1341     1      1               1                 250.0                             7                         2015       1                 35               2012         0\n",
       "84     85            5   7791        971     1      1               1                1870.0                            10                         2011       0                 31               2015         0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_attributes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "255af71a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.405086Z",
     "start_time": "2021-10-29T16:52:34.405086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_holiday</th>\n",
       "      <th>store_type</th>\n",
       "      <th>assortment</th>\n",
       "      <th>promo_interval</th>\n",
       "      <th>month_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "      <td>Jul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>Jul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "      <td>Jul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>Mar,Jun,Sept,Dec</td>\n",
       "      <td>Jul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>Jul</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_holiday store_type assortment    promo_interval month_map\n",
       "16             0          a          a   Jan,Apr,Jul,Oct       Jul\n",
       "33             0          c          a                         Jul\n",
       "50             0          a          c   Jan,Apr,Jul,Oct       Jul\n",
       "67             0          a          c  Mar,Jun,Sept,Dec       Jul\n",
       "84             0          b          a                         Jul"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_attributes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86abcc",
   "metadata": {},
   "source": [
    "### 1.7.1. Numerical Atributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65a3728",
   "metadata": {},
   "source": [
    "Aqui parece ser mais razoável selecionar as colunas que façam sentido ter estatísticas.\n",
    "Algumas variáveis aqui são categóricas mas o encoding já está feito como:\n",
    "- store\n",
    "- day_of_week\n",
    "- promo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "365971ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.406085Z",
     "start_time": "2021-10-29T16:52:34.406085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>sales</th>\n",
       "      <th>customers</th>\n",
       "      <th>open</th>\n",
       "      <th>promo</th>\n",
       "      <th>school_holiday</th>\n",
       "      <th>competition_distance</th>\n",
       "      <th>competition_open_since_month</th>\n",
       "      <th>competition_open_since_year</th>\n",
       "      <th>promo2</th>\n",
       "      <th>promo2_since_week</th>\n",
       "      <th>promo2_since_year</th>\n",
       "      <th>is_promo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59574.000000</td>\n",
       "      <td>59574.000000</td>\n",
       "      <td>59574.000000</td>\n",
       "      <td>59574.000000</td>\n",
       "      <td>59574.000000</td>\n",
       "      <td>59574.000000</td>\n",
       "      <td>59574.000000</td>\n",
       "      <td>59574.000000</td>\n",
       "      <td>59574.000000</td>\n",
       "      <td>59574.000000</td>\n",
       "      <td>59574.000000</td>\n",
       "      <td>59574.000000</td>\n",
       "      <td>59574.000000</td>\n",
       "      <td>59574.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.942727</td>\n",
       "      <td>3.998271</td>\n",
       "      <td>5626.912428</td>\n",
       "      <td>614.360056</td>\n",
       "      <td>0.832209</td>\n",
       "      <td>0.381609</td>\n",
       "      <td>0.175060</td>\n",
       "      <td>5684.942760</td>\n",
       "      <td>7.216621</td>\n",
       "      <td>2010.226407</td>\n",
       "      <td>0.566522</td>\n",
       "      <td>24.030164</td>\n",
       "      <td>2012.690905</td>\n",
       "      <td>0.186994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>318.996803</td>\n",
       "      <td>1.997400</td>\n",
       "      <td>3630.477237</td>\n",
       "      <td>403.144225</td>\n",
       "      <td>0.373684</td>\n",
       "      <td>0.485786</td>\n",
       "      <td>0.380021</td>\n",
       "      <td>6549.599528</td>\n",
       "      <td>3.287028</td>\n",
       "      <td>4.615929</td>\n",
       "      <td>0.495559</td>\n",
       "      <td>13.936008</td>\n",
       "      <td>1.673691</td>\n",
       "      <td>0.389910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>289.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3838.000000</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>620.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>561.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5633.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2490.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>833.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7581.750000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8260.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1105.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>31415.000000</td>\n",
       "      <td>3145.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25430.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              store   day_of_week         sales     customers          open         promo  school_holiday  competition_distance  competition_open_since_month  competition_open_since_year        promo2  promo2_since_week  promo2_since_year      is_promo\n",
       "count  59574.000000  59574.000000  59574.000000  59574.000000  59574.000000  59574.000000    59574.000000          59574.000000                  59574.000000                 59574.000000  59574.000000       59574.000000       59574.000000  59574.000000\n",
       "mean     562.942727      3.998271   5626.912428    614.360056      0.832209      0.381609        0.175060           5684.942760                      7.216621                  2010.226407      0.566522          24.030164        2012.690905      0.186994\n",
       "std      318.996803      1.997400   3630.477237    403.144225      0.373684      0.485786        0.380021           6549.599528                      3.287028                     4.615929      0.495559          13.936008           1.673691      0.389910\n",
       "min       17.000000      1.000000      0.000000      0.000000      0.000000      0.000000        0.000000             50.000000                      1.000000                  1999.000000      0.000000           1.000000        2009.000000      0.000000\n",
       "25%      289.000000      2.000000   3838.000000    416.000000      1.000000      0.000000        0.000000            620.000000                      4.000000                  2007.000000      0.000000          12.000000        2012.000000      0.000000\n",
       "50%      561.000000      4.000000   5633.000000    609.000000      1.000000      0.000000        0.000000           2490.000000                      7.000000                  2012.000000      1.000000          23.000000        2013.000000      0.000000\n",
       "75%      833.000000      6.000000   7581.750000    832.000000      1.000000      1.000000        0.000000           8260.000000                     10.000000                  2014.000000      1.000000          35.000000        2014.000000      0.000000\n",
       "max     1105.000000      7.000000  31415.000000   3145.000000      1.000000      1.000000        1.000000          25430.000000                     12.000000                  2015.000000      1.000000          52.000000        2015.000000      1.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Central Tendency - mean, median \n",
    "\n",
    "m = num_attributes.describe()\n",
    "#ct1 = pd.DataFrame( num_attributes.apply( np.mean ) ).T\n",
    "#ct2 = pd.DataFrame( num_attributes.apply( np.median ) ).T\n",
    "\n",
    "# dispersion - std, min, max, range, skew, kurtosis\n",
    "#d1 = pd.DataFrame( num_attributes.apply( np.std ) ).T \n",
    "#d2 = pd.DataFrame( num_attributes.apply( min ) ).T \n",
    "#d3 = pd.DataFrame( num_attributes.apply( max ) ).T \n",
    "#d4 = pd.DataFrame( num_attributes.apply( lambda x: x.max() - x.min() ) ).T \n",
    "#d5 = pd.DataFrame( num_attributes.apply( lambda x: x.skew() ) ).T \n",
    "#d6 = pd.DataFrame( num_attributes.apply( lambda x: x.kurtosis() ) ).T \n",
    "\n",
    "# concatenar\n",
    "#m = pd.concat( [d2, d3, d4, ct1, ct2, d1, d5, d6] ).T.reset_index()\n",
    "#m.columns = ['attributes', 'min', 'max', 'range', 'mean', 'median', 'std', 'skew', 'kurtosis']\n",
    "#m\n",
    "#ct1\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118ebc5c",
   "metadata": {},
   "source": [
    "### 1.7.2. Categorical Atributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d49fa6ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.407082Z",
     "start_time": "2021-10-29T16:52:34.407082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state_holiday      4\n",
       "store_type         4\n",
       "assortment         2\n",
       "promo_interval     4\n",
       "month_map         12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_attributes.apply( lambda x: x.unique().shape[0] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2530ac33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.408080Z",
     "start_time": "2021-10-29T16:52:34.408080Z"
    }
   },
   "outputs": [],
   "source": [
    "if(show_graphics):\n",
    "    \n",
    "    aux = df1[(df1['state_holiday'] != '0') & (df1['sales'] > 0)]\n",
    "\n",
    "    plt.subplot( 1, 3, 1 )\n",
    "    sns.boxplot( x='state_holiday', y='sales', data=aux )\n",
    "\n",
    "    plt.subplot( 1, 3, 2 )\n",
    "    sns.boxplot( x='store_type', y='sales', data=aux )\n",
    "\n",
    "    plt.subplot( 1, 3, 3 )\n",
    "    sns.boxplot( x='assortment', y='sales', data=aux )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d874333",
   "metadata": {},
   "source": [
    "# 2.0. FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52fe0089",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.409076Z",
     "start_time": "2021-10-29T16:52:34.409076Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d94770",
   "metadata": {},
   "source": [
    "## 2.1. Hypothesys Mindmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6224fa3",
   "metadata": {},
   "source": [
    "Fazer um mapa mental com as hipóteses a serem levantadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a9d175",
   "metadata": {},
   "source": [
    "## 2.2. Criacao das Hipoteses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e884b2e",
   "metadata": {},
   "source": [
    "Registro da lista de hipóteses a serem avaliadas com brainstorming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c139f357",
   "metadata": {},
   "source": [
    "## 2.3. Lista Final de Hipóteses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237c05d",
   "metadata": {},
   "source": [
    "Apenas escolher algumas hipóteses aparentemente mais relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b8ec4a",
   "metadata": {},
   "source": [
    "## 2.4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9a00b6",
   "metadata": {},
   "source": [
    "Derivar algumas variáveis para facilitar a avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "503d9415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.410074Z",
     "start_time": "2021-10-29T16:52:34.410074Z"
    }
   },
   "outputs": [],
   "source": [
    "# Derivando datas como variáveis categóricas\n",
    "# year\n",
    "df2['year'] = df2['date'].dt.year\n",
    "\n",
    "# month\n",
    "df2['month'] = df2['date'].dt.month\n",
    "\n",
    "# day\n",
    "df2['day'] = df2['date'].dt.day\n",
    "\n",
    "# week of year\n",
    "df2['week_of_year'] = df2['date'].dt.weekofyear\n",
    "\n",
    "# year week\n",
    "df2['year_week'] = df2['date'].dt.strftime( '%Y-%W' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f76ac5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.412068Z",
     "start_time": "2021-10-29T16:52:34.412068Z"
    }
   },
   "outputs": [],
   "source": [
    "# competition since\n",
    "\n",
    "# criando uma única feature para dizer a data de início da promoção\n",
    "df2['competition_since'] = df2.apply( lambda x: datetime.datetime( year=x['competition_open_since_year'], month=x['competition_open_since_month'],day=1 ), axis=1 )\n",
    "\n",
    "# calcula o timedelta do início da promoção para a data do registro\n",
    "df2['competition_time_month'] = ( ( df2['date'] - df2['competition_since'] )/30 ).apply( lambda x: x.days ).astype( int64 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "faa978c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.414063Z",
     "start_time": "2021-10-29T16:52:34.414063Z"
    }
   },
   "outputs": [],
   "source": [
    "# promo since\n",
    "\n",
    "# cria uma str com o formato da data\n",
    "df2['promo_since'] = df2['promo2_since_year'].astype( str ) + '-' + df2['promo2_since_week'].astype( str )\n",
    "\n",
    "# transforma a str em data\n",
    "df2['promo_since'] = df2['promo_since'].apply( lambda x: datetime.datetime.strptime( x + '-1', '%Y-%W-%w' ) - datetime.timedelta( days=7 ) )\n",
    "\n",
    "# calcula o timedelta da promoção em semanas\n",
    "df2['promo_time_week'] = ( ( df2['date'] - df2['promo_since'] )/7 ).apply( lambda x: x.days ).astype( int64 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5070ab2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.416061Z",
     "start_time": "2021-10-29T16:52:34.416061Z"
    }
   },
   "outputs": [],
   "source": [
    "# competition strenght - indica de forma mais direta a interferência da competição\n",
    "\n",
    "df2['competition_str'] = 1/df2['competition_distance']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43877c67",
   "metadata": {},
   "source": [
    "# PASSO 03 - FILTRAGEM DE VARIÁVEIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90e8e608",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.417056Z",
     "start_time": "2021-10-29T16:52:34.417056Z"
    }
   },
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bb6fd6",
   "metadata": {},
   "source": [
    "## Filtragem das Linhas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d095536c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.418051Z",
     "start_time": "2021-10-29T16:52:34.418051Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exclui linhas quando as lojas estavam fechadas ou não houve vendas\n",
    "df3 = df3[(df3['open'] != 0) & (df3['sales'] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0d8dc4",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fae135f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.420047Z",
     "start_time": "2021-10-29T16:52:34.420047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['store', 'day_of_week', 'date', 'sales', 'promo', 'state_holiday',\n",
       "       'school_holiday', 'store_type', 'assortment', 'promo2', 'is_promo',\n",
       "       'year', 'month', 'day', 'week_of_year', 'year_week',\n",
       "       'competition_time_month', 'promo_time_week', 'competition_str'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Excluindo features que não fazem sentido para modelagem\n",
    "cols_drop = ['customers', 'open', 'promo_interval', 'month_map', 'competition_open_since_year', 'competition_open_since_month', 'competition_since', 'promo_since', 'promo2_since_year', 'promo2_since_week', 'competition_distance' ]\n",
    "df3 = df3.drop( cols_drop, axis=1 )\n",
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4cbd7a54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.421045Z",
     "start_time": "2021-10-29T16:52:34.421045Z"
    }
   },
   "outputs": [],
   "source": [
    "num_attributes_list = ['competition_str',\n",
    "                       'promo_time_week',\n",
    "                       'competition_time_month']\n",
    "cat_attributes_list = ['store',\n",
    "                       'day_of_week',\n",
    "                       'promo',\n",
    "                       'state_holiday',\n",
    "                       'school_holiday',\n",
    "                       'store_type',\n",
    "                       'assortment',\n",
    "                       'is_promo',\n",
    "                       'day',\n",
    "                       'month',\n",
    "                       'week_of_year',\n",
    "                       'year_week']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1815229",
   "metadata": {},
   "source": [
    "# EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73b6150c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.422042Z",
     "start_time": "2021-10-29T16:52:34.422042Z"
    }
   },
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f518e89",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b30dfc",
   "metadata": {},
   "source": [
    "É interessante que as variáveis tenham distribuição normal para melhor performance dos modelos de ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e1a452",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Numercial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16aff822",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.423039Z",
     "start_time": "2021-10-29T16:52:34.423039Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if(show_graphics):\n",
    "    for i, var in enumerate(num_attributes_list):\n",
    "        plt.subplot(3, 1, i+1)\n",
    "        sns.histplot(df4[var])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa0a59f",
   "metadata": {},
   "source": [
    "### Target Variable - sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f288c09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.424036Z",
     "start_time": "2021-10-29T16:52:34.424036Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if(show_graphics):\n",
    "    sns.distplot(df4['sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a079c77",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Numerical Features vs Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e2462c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.426031Z",
     "start_time": "2021-10-29T16:52:34.426031Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if(show_graphics):\n",
    "\n",
    "    for i , attribute in enumerate(num_attributes_list):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        sns.regplot(attribute, 'sales', data = df4[['sales', attribute]], line_kws={'color': 'r'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c3b6ca",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e58411ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.427028Z",
     "start_time": "2021-10-29T16:52:34.427028Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if(show_graphics):\n",
    "\n",
    "    for i , attribute in enumerate(cat_attributes_list):\n",
    "        aux = df4[['sales', attribute]].groupby(attribute).mean().reset_index()\n",
    "        plt.subplot(4, 3, i+1)\n",
    "        sns.barplot(x = attribute, y= 'sales', data = aux)\n",
    "\n",
    "        #sns.regplot(attribute, 'sales', data = num_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a2855",
   "metadata": {},
   "source": [
    "## Multivariate Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2644dd",
   "metadata": {},
   "source": [
    "### Numerical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e03d7ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.429023Z",
     "start_time": "2021-10-29T16:52:34.429023Z"
    }
   },
   "outputs": [],
   "source": [
    "if(show_graphics):\n",
    "\n",
    "    num_correlation = df4[num_attributes_list].corr(method = 'pearson')\n",
    "    sns.heatmap(num_correlation, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44949db",
   "metadata": {},
   "source": [
    "### Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "947c086d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.431017Z",
     "start_time": "2021-10-29T16:52:34.431017Z"
    }
   },
   "outputs": [],
   "source": [
    "aux_list = ['state_holiday', 'store_type', 'assortment']\n",
    "aux_dict = {}\n",
    "\n",
    "for var1 in aux_list:\n",
    "    a_list = []\n",
    "    for var2 in aux_list:\n",
    "        a = cramer_v(df4[var1], df4[var2])\n",
    "        a_list.append(a)\n",
    "    aux_dict[var1] = a_list\n",
    "     \n",
    "aux_df = pd.DataFrame(aux_dict)\n",
    "aux_df = aux_df.set_index(aux_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de263b7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.432014Z",
     "start_time": "2021-10-29T16:52:34.432014Z"
    }
   },
   "outputs": [],
   "source": [
    "if(show_graphics):\n",
    "    sns.heatmap( aux_df, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303c9ee0",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2502a85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.433012Z",
     "start_time": "2021-10-29T16:52:34.433012Z"
    }
   },
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e11c7eb",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad259f6",
   "metadata": {},
   "source": [
    "A normalizção cabe para variáveis com distribuição normal, mas, aparentemente, não é o caso de nenhuma variável."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd5864c",
   "metadata": {},
   "source": [
    "## Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "62e0012b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.434009Z",
     "start_time": "2021-10-29T16:52:34.434009Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# competition_str\n",
    "rs = RobustScaler()\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "df5['competition_str'] = rs.fit_transform(df5[['competition_str']])\n",
    "pickle.dump(rs, open('parameter/encoding_competition_str.pkl', 'wb'))\n",
    "\n",
    "# competition time_month\n",
    "df5['competition_time_month'] = mms.fit_transform(df5[['competition_time_month']])\n",
    "pickle.dump(mms, open('parameter/encoding_competition_time_month.pkl', 'wb'))\n",
    "\n",
    "# promo_time_week\n",
    "df5['promo_time_week'] = mms.fit_transform(df5[['promo_time_week']])\n",
    "pickle.dump(mms, open('parameter/encoding_promo_time_week.pkl', 'wb'))\n",
    "\n",
    "# year\n",
    "df5['year'] = mms.fit_transform(df5[['year']])\n",
    "pickle.dump(mms, open('parameter/encoding_year.pkl', 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8490c203",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94d39b74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.436013Z",
     "start_time": "2021-10-29T16:52:34.436013Z"
    }
   },
   "outputs": [],
   "source": [
    "# state_holiday - One Hot Encoding\n",
    "df5 = pd.get_dummies(df5, prefix=['state_holiday'], columns=['state_holiday'])\n",
    "\n",
    "# store_type - Label Encoding\n",
    "le = LabelEncoder()\n",
    "df5['store_type'] = le.fit_transform(df5['store_type'])\n",
    "pickle.dump(le, open('parameter/encoding_store_type.pkl', 'wb'))\n",
    "\n",
    "\n",
    "# assortment - Ordinal Encoding\n",
    "assortment_dict = {'a':1,'b':2,'c':3}\n",
    "df5['assortment'] = df5['assortment'].map(assortment_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f9f4b",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013c3568",
   "metadata": {},
   "source": [
    "### Response variable transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f72f3",
   "metadata": {},
   "source": [
    "Log is applyed to 'sales' to better fit the variable distribuition to a normal curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3d37df9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.437003Z",
     "start_time": "2021-10-29T16:52:34.437003Z"
    }
   },
   "outputs": [],
   "source": [
    "df5['sales'] = np.log1p(df5['sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d5d85c",
   "metadata": {},
   "source": [
    "### Nature transformation for cyclical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d390f473",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.438000Z",
     "start_time": "2021-10-29T16:52:34.438000Z"
    }
   },
   "outputs": [],
   "source": [
    "# day of week\n",
    "df5['day_of_week_sin'] = df5['day_of_week'].apply(lambda x : np.sin(x*(2.*np.pi/7)))\n",
    "df5['day_of_week_cos'] = df5['day_of_week'].apply(lambda x : np.cos(x*(2.*np.pi/7)))\n",
    "\n",
    "# month\n",
    "df5['month_sin'] = df5['month'].apply(lambda x : np.sin(x*(2.*np.pi/12)))\n",
    "df5['month_cos'] = df5['month'].apply(lambda x : np.cos(x*(2.*np.pi/12)))\n",
    "\n",
    "# day\n",
    "df5['day_sin'] = df5['day'].apply(lambda x : np.sin(x*(2.*np.pi/30)))\n",
    "df5['day_cos'] = df5['day'].apply(lambda x : np.cos(x*(2.*np.pi/30)))\n",
    "\n",
    "# week of year\n",
    "df5['week_of_year_sin'] = df5['week_of_year'].apply(lambda x : np.sin(x*(2.*np.pi/52)))\n",
    "df5['week_of_year_cos'] = df5['week_of_year'].apply(lambda x : np.cos(x*(2.*np.pi/52)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0271c3af",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb943b05",
   "metadata": {},
   "source": [
    "* Seleção univariada utiliza a correlação para selecionar as variáveis\n",
    "* Seleção por importância treina modelos como random forest ou regression linear (verifica coeficientes) para escolher as variáveis\n",
    "* Seleção por Subset:\n",
    "    * Selecione uma variável aleaoriamente, treine um modelo (random forest ou xgboost) e calcule a performance\n",
    "    * Loop: Adicione outra variável e verifique se a perfomance aumentou. Se sim, manter a variável.\n",
    "    * O Boruta funciona dessa forma, mas comparando com a melhor variável shadow e usando o p-value.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49933b07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.438997Z",
     "start_time": "2021-10-29T16:52:34.438997Z"
    }
   },
   "outputs": [],
   "source": [
    "df6 = df5.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf831c2",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bbea2b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.439995Z",
     "start_time": "2021-10-29T16:52:34.439995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['store', 'day_of_week', 'date', 'sales', 'promo', 'school_holiday',\n",
       "       'store_type', 'assortment', 'promo2', 'is_promo', 'year', 'month',\n",
       "       'day', 'week_of_year', 'year_week', 'competition_time_month',\n",
       "       'promo_time_week', 'competition_str', 'state_holiday_0',\n",
       "       'state_holiday_a', 'state_holiday_b', 'state_holiday_c',\n",
       "       'day_of_week_sin', 'day_of_week_cos', 'month_sin', 'month_cos',\n",
       "       'day_sin', 'day_cos', 'week_of_year_sin', 'week_of_year_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6269d65e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.440992Z",
     "start_time": "2021-10-29T16:52:34.440992Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_drop = ['week_of_year', 'day', 'month', 'day_of_week']\n",
    "df6 = df6.drop(cols_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "70e713d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.442985Z",
     "start_time": "2021-10-29T16:52:34.442985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Min date: 2013-01-01 00:00:00\n",
      "Train Max date: 2015-06-18 00:00:00\n",
      "\n",
      "\n",
      "Test  Min date: 2015-06-19 00:00:00\n",
      "Test  Max date: 2015-07-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "train_date_limit = df6[['store', 'date']].groupby('store').max().reset_index()['date'][0] - datetime.timedelta(days = 6*7)\n",
    "\n",
    "X_train = df6[df6['date'] < train_date_limit ]\n",
    "y_train = X_train['sales']\n",
    "\n",
    "\n",
    "X_test = df6[df6['date'] >= train_date_limit ]\n",
    "y_test = X_test['sales']\n",
    "\n",
    "print( 'Train Min date: {}'.format(X_train['date'].min()))\n",
    "print( 'Train Max date: {}'.format(X_train['date'].max()))\n",
    "print('\\n')\n",
    "print( 'Test  Min date: {}'.format(X_test['date'].min()))\n",
    "print( 'Test  Max date: {}'.format(X_test['date'].max()))\n",
    "\n",
    "# não parece razoável dropar a data, mas como os dados da data estão contidos em outros atributos, ok\n",
    "X_train_n = X_train.drop(['date', 'sales'], axis = 1).values\n",
    "y_train_n = y_train.values.ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3ac866",
   "metadata": {},
   "source": [
    "## Boruta Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c90486e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.443983Z",
     "start_time": "2021-10-29T16:52:34.443983Z"
    }
   },
   "outputs": [],
   "source": [
    "if(run_boruta):\n",
    "    \n",
    "    # define RandomForestRegressor\n",
    "    rf = RandomForestRegressor(n_jobs = -1)\n",
    "    \n",
    "    boruta = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=42).fit(X_train_n, y_train_n)\n",
    "    \n",
    "    cols_selected = boruta.support_.tolist()\n",
    "    cols_selected_boruta = X\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bebe115",
   "metadata": {},
   "source": [
    "### Best Features from Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe855e3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.444980Z",
     "start_time": "2021-10-29T16:52:34.444980Z"
    }
   },
   "outputs": [],
   "source": [
    "if(run_boruta):\n",
    "    cols_selected = boruta.support_.tolist()\n",
    "\n",
    "    # best features\n",
    "    X_train_fs = X_train.drop( ['date', 'sales'], axis=1 )\n",
    "    cols_selected_boruta = X_train_fs.iloc[:, cols_selected].columns.to_list()\n",
    "\n",
    "    # not selected boruta\n",
    "    cols_not_selected_boruta = list( np.setdiff1d( X_train_fs.columns, cols_selected_boruta ) )\n",
    "else:\n",
    "    # Manual feature selection\n",
    "    cols_selected_boruta = ['store',\n",
    "                            'promo',\n",
    "                            'store_type',\n",
    "                            'assortment',\n",
    "                            'promo2',\n",
    "                            'competition_time_month',\n",
    "                            'promo_time_week',\n",
    "                            'competition_str',\n",
    "                            'day_of_week_sin',\n",
    "                            'day_of_week_cos',\n",
    "                            'month_cos',\n",
    "                            'day_sin',\n",
    "                            'day_cos',\n",
    "                            'week_of_year_cos'\n",
    "                           ]\n",
    "    \n",
    "    cols_not_selected_boruta = ['is_promo', 'month_sin', 'school_holiday', 'state_holiday_0',\n",
    "       'state_holiday_a', 'state_holiday_b', 'state_holiday_c', 'week_of_year_sin', 'year']\n",
    "\n",
    "\n",
    "# columns to add\n",
    "feat_to_add = ['date', 'sales']\n",
    "\n",
    "cols_selected_boruta_full = cols_selected_boruta.copy()\n",
    "cols_selected_boruta_full.extend( feat_to_add )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c69607f",
   "metadata": {},
   "source": [
    "# Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd4228b",
   "metadata": {},
   "source": [
    "* Average Model - Modelo de referência\n",
    "* Linear Regression\n",
    "* Linear Regression Regularized (Lasso e Ridge)\n",
    "* Random Forest Regressor\n",
    "* XGBoost Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f5550517",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.445979Z",
     "start_time": "2021-10-29T16:52:34.445979Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train[cols_selected_boruta]\n",
    "X_test  = X_test[cols_selected_boruta]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecb99a0",
   "metadata": {},
   "source": [
    "## Average Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "332faff7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.446976Z",
     "start_time": "2021-10-29T16:52:34.446976Z"
    }
   },
   "outputs": [],
   "source": [
    "aux1 = X_test.copy()\n",
    "aux1['sales'] = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6fa80e16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.448971Z",
     "start_time": "2021-10-29T16:52:34.448971Z"
    }
   },
   "outputs": [],
   "source": [
    "# prediction\n",
    "\n",
    "aux2 = aux1[['store', 'sales']].groupby('store').mean().reset_index().rename(columns = {'sales' : 'predictions'})\n",
    "aux1 = pd.merge(aux1, aux2, how = 'left', on='store')\n",
    "\n",
    "yhat_baseline = aux1['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a61dd884",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.449966Z",
     "start_time": "2021-10-29T16:52:34.449966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Average Model</td>\n",
       "      <td>1308.743555</td>\n",
       "      <td>0.331512</td>\n",
       "      <td>1768.353952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model Name          MAE      MAPE         RMSE\n",
       "0  Average Model  1308.743555  0.331512  1768.353952"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performance\n",
    "\n",
    "baseline_result = ml_error('Average Model', np.expm1(y_test), np.expm1(yhat_baseline))\n",
    "baseline_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45009b78",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb176e6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.451961Z",
     "start_time": "2021-10-29T16:52:34.451961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1618.505794</td>\n",
       "      <td>0.248724</td>\n",
       "      <td>2363.620074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model Name          MAE      MAPE         RMSE\n",
       "0  Linear Regression  1618.505794  0.248724  2363.620074"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "lr = LinearRegression()\n",
    "lr.fit( X_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_lr = lr.predict( X_test )\n",
    "\n",
    "# performance\n",
    "lr_result = ml_error( 'Linear Regression', np.expm1( y_test ), np.expm1( yhat_lr ) )\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98990c1e",
   "metadata": {},
   "source": [
    "## Linear Regression Model Relularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b04700f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.453956Z",
     "start_time": "2021-10-29T16:52:34.453956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>1644.541822</td>\n",
       "      <td>0.250943</td>\n",
       "      <td>2407.794987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name          MAE      MAPE         RMSE\n",
       "0      Lasso  1644.541822  0.250943  2407.794987"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "lrr = Lasso(alpha = 0.01).fit( X_train, y_train )\n",
    "\n",
    "# prediction\n",
    "yhat_lrr = lrr.predict( X_test )\n",
    "\n",
    "# performance\n",
    "lrr_result = ml_error( 'Lasso', np.expm1( y_test ), np.expm1( yhat_lrr ) )\n",
    "lrr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0df3c0",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c23b3a19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.454953Z",
     "start_time": "2021-10-29T16:52:34.454953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>711.614893</td>\n",
       "      <td>0.110912</td>\n",
       "      <td>991.766987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model Name         MAE      MAPE        RMSE\n",
       "0  Random Forest  711.614893  0.110912  991.766987"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "rf = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42).fit(X_train, y_train)\n",
    "\n",
    "# prediction\n",
    "yhat_rf = rf.predict(X_test)\n",
    "\n",
    "# performance\n",
    "rf_result = ml_error('Random Forest', np.expm1(y_test), np.expm1(yhat_rf))\n",
    "rf_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea438166",
   "metadata": {},
   "source": [
    "## XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c42c162",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.456949Z",
     "start_time": "2021-10-29T16:52:34.456949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>6427.166832</td>\n",
       "      <td>0.950293</td>\n",
       "      <td>6950.909755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name          MAE      MAPE         RMSE\n",
       "0    XGBoost  6427.166832  0.950293  6950.909755"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model_xgb = xgb.XGBRegressor(objective = 'reg:squarederror',\n",
    "                             n_estimators=100,\n",
    "                             eta = 0.01,\n",
    "                             subsample = 0.7\n",
    "                            ).fit(X_train, y_train)\n",
    "\n",
    "# prediction\n",
    "yhat_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "# performance\n",
    "xgb_result = ml_error('XGBoost', np.expm1(y_test), np.expm1(yhat_xgb))\n",
    "xgb_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30574b8",
   "metadata": {},
   "source": [
    "## Model Performance Comparisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a53711f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.457946Z",
     "start_time": "2021-10-29T16:52:34.457946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>711.614893</td>\n",
       "      <td>0.110912</td>\n",
       "      <td>991.766987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Average Model</td>\n",
       "      <td>1308.743555</td>\n",
       "      <td>0.331512</td>\n",
       "      <td>1768.353952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1618.505794</td>\n",
       "      <td>0.248724</td>\n",
       "      <td>2363.620074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>1644.541822</td>\n",
       "      <td>0.250943</td>\n",
       "      <td>2407.794987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>6427.166832</td>\n",
       "      <td>0.950293</td>\n",
       "      <td>6950.909755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model Name          MAE      MAPE         RMSE\n",
       "0      Random Forest   711.614893  0.110912   991.766987\n",
       "0      Average Model  1308.743555  0.331512  1768.353952\n",
       "0  Linear Regression  1618.505794  0.248724  2363.620074\n",
       "0              Lasso  1644.541822  0.250943  2407.794987\n",
       "0            XGBoost  6427.166832  0.950293  6950.909755"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_result = pd.concat([baseline_result, lr_result, lrr_result, rf_result, xgb_result])\n",
    "modeling_result.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7128ef",
   "metadata": {},
   "source": [
    "## Cross Validation Performance Comparisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f4b905bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.459940Z",
     "start_time": "2021-10-29T16:52:34.459940Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_full = df6[df6['date'] < train_date_limit ][cols_selected_boruta_full]\n",
    "\n",
    "lr_result_cv = cross_validation(X_train_full, 5, 'Linear Regression', lr, verbose =  False)\n",
    "lrr_result_cv = cross_validation(X_train_full, 5, 'Lasso', lrr, verbose =  False)\n",
    "rf_result_cv = cross_validation(X_train_full, 5, 'Random Forest', rf, verbose =  False)\n",
    "xgb_result_cv = cross_validation(X_train_full, 5, 'XGB', model_xgb, verbose =  False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "561015a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.460939Z",
     "start_time": "2021-10-29T16:52:34.460939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE CV</th>\n",
       "      <th>MAPE CV</th>\n",
       "      <th>RMSE CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>800.6 +/- 176.87</td>\n",
       "      <td>0.11 +/- 0.02</td>\n",
       "      <td>1197.61 +/- 249.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1850.08 +/- 334.6</td>\n",
       "      <td>0.26 +/- 0.02</td>\n",
       "      <td>2724.08 +/- 524.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>1875.99 +/- 370.17</td>\n",
       "      <td>0.26 +/- 0.01</td>\n",
       "      <td>2774.96 +/- 558.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB</td>\n",
       "      <td>6811.76 +/- 626.91</td>\n",
       "      <td>0.95 +/- 0.0</td>\n",
       "      <td>7375.16 +/- 721.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model Name              MAE CV        MAPE CV             RMSE CV\n",
       "0      Random Forest    800.6 +/- 176.87  0.11 +/- 0.02  1197.61 +/- 249.24\n",
       "0  Linear Regression   1850.08 +/- 334.6  0.26 +/- 0.02   2724.08 +/- 524.9\n",
       "0              Lasso  1875.99 +/- 370.17  0.26 +/- 0.01  2774.96 +/- 558.03\n",
       "0                XGB  6811.76 +/- 626.91   0.95 +/- 0.0  7375.16 +/- 721.15"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_result_cv = pd.concat([lr_result_cv, lrr_result_cv, rf_result_cv, xgb_result_cv])\n",
    "modeling_result_cv.sort_values('RMSE CV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4ce82c",
   "metadata": {},
   "source": [
    "# Hyperparameter Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb11950b",
   "metadata": {},
   "source": [
    "* Random Search - Define aleatoriamente os valores em uma tabela, define um número de interações e testa o melhor.\n",
    "    * Método mais rápido mas impreciso.\n",
    "* Grid Search - Procura todas as combinações possíveis\n",
    "* Bayesian Search - Usa teoria de Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc1da8b",
   "metadata": {},
   "source": [
    "## Random Search for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0069e904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.461934Z",
     "start_time": "2021-10-29T16:52:34.461934Z"
    }
   },
   "outputs": [],
   "source": [
    "random_grid  = {\n",
    "    'n_estimators': [50, 80, 100, 150, 200, 350, 500, 900, 1300, 1700],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee073a4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.462933Z",
     "start_time": "2021-10-29T16:52:34.462933Z"
    }
   },
   "outputs": [],
   "source": [
    "if fine_tunning:\n",
    "    # model\n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    rf_random = RandomizedSearchCV(estimator = rf,\n",
    "                                   param_distributions = random_grid,\n",
    "                                   n_iter = 20,\n",
    "                                   cv = 2,\n",
    "                                   verbose=2,\n",
    "                                   random_state=42,\n",
    "                                   n_jobs = -1)\n",
    "\n",
    "\n",
    "    rf_random.fit(X_train, y_train)\n",
    "\n",
    "    print(rf_random.best_params_)\n",
    "else:\n",
    "    best_params = {'n_estimators': 350, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': False}\n",
    "    rf_random = RandomForestRegressor(n_estimators = best_params['n_estimators'],\n",
    "                                      min_samples_split = best_params['min_samples_split'],\n",
    "                                      min_samples_leaf = best_params['min_samples_leaf'],\n",
    "                                      max_features = best_params['max_features'],\n",
    "                                      max_depth = best_params['max_depth'],\n",
    "                                      bootstrap = best_params['bootstrap'],\n",
    "                                      random_state=42,\n",
    "                                      n_jobs = -1                                  \n",
    "                                     ).fit(X_train, y_train)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ae91161e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.463931Z",
     "start_time": "2021-10-29T16:52:34.463931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest HPT</td>\n",
       "      <td>688.928838</td>\n",
       "      <td>0.106288</td>\n",
       "      <td>983.855366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model Name         MAE      MAPE        RMSE\n",
       "0  Random Forest HPT  688.928838  0.106288  983.855366"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    yhat_rf_hpt = rf_random.predict(X_test)\n",
    "\n",
    "    rf_result = ml_error('Random Forest HPT', np.expm1(y_test), np.expm1(yhat_rf_hpt))\n",
    "    rf_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8708d493",
   "metadata": {},
   "source": [
    "# Error Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bb352542",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.465925Z",
     "start_time": "2021-10-29T16:52:34.465925Z"
    }
   },
   "outputs": [],
   "source": [
    "df7 =  df6[df6['date'] >= train_date_limit ][cols_selected_boruta_full]\n",
    "\n",
    "# rescale\n",
    "df7['sales'] = np.expm1(df7['sales'])\n",
    "df7['predictions'] = np.expm1(yhat_rf_hpt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752e9bc9",
   "metadata": {},
   "source": [
    "## Business Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "03ebc195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.466922Z",
     "start_time": "2021-10-29T16:52:34.466922Z"
    }
   },
   "outputs": [],
   "source": [
    "# quantify sales in the entire period\n",
    "# sum of predictions\n",
    "df7_grouped = df7[['store', 'predictions']].groupby('store').sum().reset_index()\n",
    "\n",
    "# MAE and MAPE\n",
    "aux1 = df7[['store', 'sales', 'predictions']].groupby('store').apply(lambda x: mean_absolute_error(x['sales'], x['predictions'])).reset_index().rename(columns={0:'MAE'})\n",
    "aux2 = df7[['store', 'sales', 'predictions']].groupby('store').apply(lambda x: mean_absolute_percentage_error(x['sales'], x['predictions'])).reset_index().rename(columns={0:'MAPE'})\n",
    "\n",
    "aux3 = pd.merge(aux1, aux2, how = 'inner', on = 'store')\n",
    "business = pd.merge(df7_grouped, aux3, how = 'inner', on = 'store')\n",
    "\n",
    "# Scenarios\n",
    "business['worst_scenario'] = business['predictions'] - aux3['MAE']\n",
    "business['best_scenario'] = business['predictions'] + aux3['MAE']\n",
    "\n",
    "# Reorder\n",
    "business = business[['store', 'predictions', 'worst_scenario', 'best_scenario', 'MAE', 'MAPE' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "16b9c691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.467920Z",
     "start_time": "2021-10-29T16:52:34.467920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>predictions</th>\n",
       "      <th>worst_scenario</th>\n",
       "      <th>best_scenario</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>782</td>\n",
       "      <td>218157.982639</td>\n",
       "      <td>217291.656223</td>\n",
       "      <td>219024.309055</td>\n",
       "      <td>866.326416</td>\n",
       "      <td>0.237216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>527</td>\n",
       "      <td>308846.144969</td>\n",
       "      <td>306422.040778</td>\n",
       "      <td>311270.249159</td>\n",
       "      <td>2424.104190</td>\n",
       "      <td>0.217538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>170</td>\n",
       "      <td>180809.531363</td>\n",
       "      <td>179992.820798</td>\n",
       "      <td>181626.241927</td>\n",
       "      <td>816.710564</td>\n",
       "      <td>0.216254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>153</td>\n",
       "      <td>257752.982330</td>\n",
       "      <td>256762.708798</td>\n",
       "      <td>258743.255862</td>\n",
       "      <td>990.273532</td>\n",
       "      <td>0.179910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1088</td>\n",
       "      <td>201804.905638</td>\n",
       "      <td>201003.168822</td>\n",
       "      <td>202606.642454</td>\n",
       "      <td>801.736816</td>\n",
       "      <td>0.169856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    store    predictions  worst_scenario  best_scenario          MAE      MAPE\n",
       "45    782  218157.982639   217291.656223  219024.309055   866.326416  0.237216\n",
       "30    527  308846.144969   306422.040778  311270.249159  2424.104190  0.217538\n",
       "9     170  180809.531363   179992.820798  181626.241927   816.710564  0.216254\n",
       "8     153  257752.982330   256762.708798  258743.255862   990.273532  0.179910\n",
       "63   1088  201804.905638   201003.168822  202606.642454   801.736816  0.169856"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business.sort_values('MAPE', ascending = False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0a4fd6c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.469917Z",
     "start_time": "2021-10-29T16:52:34.469917Z"
    }
   },
   "outputs": [],
   "source": [
    "if show_graphics:\n",
    "    sns.scatterplot(x= 'store', y = 'MAPE', data = business)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83a3755",
   "metadata": {},
   "source": [
    "## Total Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "42d0c47e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.471908Z",
     "start_time": "2021-10-29T16:52:34.471908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Total Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>predictions</td>\n",
       "      <td>R$ 1.6e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worst_scenario</td>\n",
       "      <td>R$ 1.6e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>best_scenario</td>\n",
       "      <td>R$ 1.6e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Scenario Total Sales\n",
       "0     predictions  R$ 1.6e+07\n",
       "1  worst_scenario  R$ 1.6e+07\n",
       "2   best_scenario  R$ 1.6e+07"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_total = business[['predictions', 'worst_scenario', 'best_scenario']].sum().reset_index().rename(columns = {'index': 'Scenario', 0: 'Total Sales'})\n",
    "business_total['Total Sales'] = business_total['Total Sales'].map('R$ {:,.2}'.format)\n",
    "business_total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1157a004",
   "metadata": {},
   "source": [
    "## Machine Learning Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c3e2be79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.472905Z",
     "start_time": "2021-10-29T16:52:34.472905Z"
    }
   },
   "outputs": [],
   "source": [
    "df7['error'] = df7['sales'] - df7['predictions']\n",
    "df7['error_rate'] = df7['error'] / df7['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ae452ad3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:52:34.473902Z",
     "start_time": "2021-10-29T16:52:34.473902Z"
    }
   },
   "outputs": [],
   "source": [
    "if show_graphics:\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.lineplot(x='date', y='sales', data = df7, label = 'SALES')\n",
    "    sns.lineplot(x='date', y='predictions', data = df7, label = 'PREDICTIONS')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.lineplot(x='date', y='error_rate', data = df7)\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.distplot(df7['error'])\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    sns.scatterplot(df7['predictions'], df7['error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14622fa5",
   "metadata": {},
   "source": [
    "# Save model to production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9b8c17d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T16:56:05.851175Z",
     "start_time": "2021-10-29T16:56:05.841202Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(rf_random, open(r'C:\\Users\\06564176686\\repos\\Store-Sales-Prediction\\model\\model_rossmann.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29b5c74",
   "metadata": {},
   "source": [
    "## Rossmann Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e3e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import inflection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "\n",
    "class Rossmann(object):\n",
    "    def __init__(self):\n",
    "        self.home_path = r'C:\\Users\\06564176686\\repos\\Store-Sales-Prediction'\n",
    "        self.encoding_competition_str        = pickle.load(open(self.home_path + 'parameter\\encoding_competition_str.pkl', 'rb'))\n",
    "        self.encoding_competition_time_month = pickle.load(open(self.home_path + 'parameter\\encoding_competition_time_month.pkl', 'rb'))\n",
    "        self.encoding_promo_time_week        = pickle.load(open(self.home_path + 'parameter\\encoding_promo_time_week.pkl', 'rb'))\n",
    "        self.encoding_year                   = pickle.load(open(self.home_path + 'parameter\\encoding_year.pkl', 'rb'))\n",
    "        self.encoding_store_type             = pickle.load(open(self.home_path + 'parameter\\encoding_store_type.pkl', 'rb'))\n",
    "\n",
    "\n",
    "    def data_cleaning(self, df1):\n",
    "        cols_old = ['Store', 'DayOfWeek', 'Date', 'Open', 'Promo',\n",
    "       'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
    "       'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
    "       'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n",
    "       'Promo2SinceYear', 'PromoInterval']\n",
    "\n",
    "        snakecase = lambda x: inflection.underscore(x)\n",
    "        cols_new = list(map(snakecase, cols_old))\n",
    "        \n",
    "        # rename\n",
    "        df1.columns = cols_new\n",
    "        \n",
    "        df1['date'] = pd.to_datetime(df1['date'])\n",
    "        \n",
    "        #competition_distance              2642\n",
    "        # Imaginar que não há competidores próximos, ou seja, distância grande.\n",
    "        faraway = 100*df1.competition_distance.max()\n",
    "        near = 50\n",
    "\n",
    "        df1['competition_distance'].fillna(faraway, inplace=True)\n",
    "        df1['competition_distance'] = df1['competition_distance'].apply(lambda x: near if x <=near else x)\n",
    "\n",
    "        # A ideia aqui é aplicar o data atual (do dado lido) para dizer depois que não há tempo com concorrente.\n",
    "        # applicar df1.date para os campos de competition open since\n",
    "\n",
    "        #competition_open_since_month    323348\n",
    "        df1['competition_open_since_month']= df1.apply(lambda x: x['date'].month if math.isnan(x['competition_open_since_month']) else x['competition_open_since_month'], axis=1)\n",
    "\n",
    "        #competition_open_since_year     323348\n",
    "        df1['competition_open_since_year']= df1.apply(lambda x: x['date'].year if math.isnan(x['competition_open_since_year']) else x['competition_open_since_year'], axis=1)\n",
    "        \n",
    "        \n",
    "        # Atribuir a data atual (da leitura) para dizer que não há tempo desde a última promo.\n",
    "        #promo2_since_week              508031\n",
    "\n",
    "        df1['promo2_since_week'] = df1.apply(lambda x: x['date'].week if math.isnan(x['promo2_since_week']) else x['promo2_since_week'], axis=1)\n",
    "\n",
    "        #promo2_since_year               508031\n",
    "        df1['promo2_since_year'] = df1.apply(lambda x: x['date'].year if math.isnan(x['promo2_since_year']) else x['promo2_since_year'], axis=1)\n",
    "\n",
    "\n",
    "        #promo_interval  \n",
    "\n",
    "        # criar month map dict\n",
    "        month_map = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "\n",
    "        # criar colunas 'month_map' com base em date\n",
    "        df1['month_map'] = df1['date'].dt.month.map(month_map)\n",
    "\n",
    "        # criar 'is_promo' comparando o map com promo_inverval\n",
    "        df1['promo_interval'].fillna('', inplace=True)\n",
    "\n",
    "\n",
    "        df1['is_promo'] = df1[['promo_interval', 'month_map']].apply(lambda x: 1 if x['month_map'] in x['promo_interval'].split(',')\n",
    "                                    else 0 ,axis=1)\n",
    "\n",
    "        \n",
    "        # competiton\n",
    "        df1['competition_open_since_month'] = df1['competition_open_since_month'].astype( int64 )\n",
    "        df1['competition_open_since_year'] = df1['competition_open_since_year'].astype( int64 )\n",
    "\n",
    "        # promo2\n",
    "        df1['promo2_since_week'] = df1['promo2_since_week'].astype( int64 )\n",
    "        df1['promo2_since_year'] = df1['promo2_since_year'].astype( int64 )\n",
    "        \n",
    "        return df1\n",
    "    \n",
    "    def feature_engineering( self, df2):\n",
    "\n",
    "        # Derivando datas como variáveis categóricas\n",
    "        # year\n",
    "        df2['year'] = df2['date'].dt.year\n",
    "\n",
    "        # month\n",
    "        df2['month'] = df2['date'].dt.month\n",
    "\n",
    "        # day\n",
    "        df2['day'] = df2['date'].dt.day\n",
    "\n",
    "        # week of year\n",
    "        df2['week_of_year'] = df2['date'].dt.weekofyear\n",
    "\n",
    "        # year week\n",
    "        df2['year_week'] = df2['date'].dt.strftime( '%Y-%W' )\n",
    "\n",
    "        # competition since\n",
    "\n",
    "        # criando uma única feature para dizer a data de início da promoção\n",
    "        df2['competition_since'] = df2.apply( lambda x: datetime.datetime( year=x['competition_open_since_year'], month=x['competition_open_since_month'],day=1 ), axis=1 )\n",
    "\n",
    "        # calcula o timedelta do início da promoção para a data do registro\n",
    "        df2['competition_time_month'] = ( ( df2['date'] - df2['competition_since'] )/30 ).apply( lambda x: x.days ).astype( int64 )\n",
    "\n",
    "        # promo since\n",
    "\n",
    "        # cria uma str com o formato da data\n",
    "        df2['promo_since'] = df2['promo2_since_year'].astype( str ) + '-' + df2['promo2_since_week'].astype( str )\n",
    "\n",
    "        # transforma a str em data\n",
    "        df2['promo_since'] = df2['promo_since'].apply( lambda x: datetime.datetime.strptime( x + '-1', '%Y-%W-%w' ) - datetime.timedelta( days=7 ) )\n",
    "\n",
    "        # calcula o timedelta da promoção em semanas\n",
    "        df2['promo_time_week'] = ( ( df2['date'] - df2['promo_since'] )/7 ).apply( lambda x: x.days ).astype( int64 )\n",
    "\n",
    "\n",
    "\n",
    "        # competition strenght - indica de forma mais direta a interferência da competição\n",
    "\n",
    "        df2['competition_str'] = 1/df2['competition_distance']\n",
    "\n",
    "\n",
    "        ## PASSO 03 - FILTRAGEM DE VARIÁVEIS\n",
    "\n",
    "\n",
    "        # Exclui linhas quando as lojas estavam fechadas ou não houve vendas\n",
    "        df2 = df2[(df2['open'] != 0)]\n",
    "\n",
    "        ## Feature Selection\n",
    "\n",
    "        #Excluindo features que não fazem sentido para modelagem\n",
    "        cols_drop = ['open', 'promo_interval', 'month_map', 'competition_open_since_year',\n",
    "                     'competition_open_since_month', 'competition_since', 'promo_since', 'promo2_since_year',\n",
    "                     'promo2_since_week', 'competition_distance' ]\n",
    "        df2 = df2.drop( cols_drop, axis=1 )\n",
    "\n",
    "        return df2\n",
    "    \n",
    "    def data_preparation(self, df5):\n",
    "    \n",
    "        ## Rescaling\n",
    "\n",
    "        # competition_str\n",
    "        df5['competition_str'] = self.encoding_competition_str.fit_transform(df5[['competition_str']].values)\n",
    "\n",
    "        # competition time_month\n",
    "        df5['competition_time_month'] = self.encoding_competition_time_month.fit_transform(df5[['competition_time_month']])\n",
    "\n",
    "        # promo_time_week\n",
    "        df5['promo_time_week'] = self.encoding_promo_time_week.fit_transform(df5[['promo_time_week']])\n",
    "\n",
    "        # year\n",
    "        df5['year'] = self.encoding_year.fit_transform(df5[['year']])\n",
    "\n",
    "\n",
    "        ## Encoding\n",
    "\n",
    "        # state_holiday - One Hot Encoding\n",
    "        df5 = pd.get_dummies(df5, prefix=['state_holiday'], columns=['state_holiday'])\n",
    "\n",
    "        # store_type - Label Encoding\n",
    "        le = LabelEncoder()\n",
    "        df5['store_type'] = self.encoding_store_type.fit_transform(df5['store_type'])\n",
    "\n",
    "        # assortment - Ordinal Encoding\n",
    "        assortment_dict = {'a':1,'b':2,'c':3}\n",
    "        df5['assortment'] = df5['assortment'].map(assortment_dict)\n",
    "\n",
    "        ## Transformations\n",
    "\n",
    "        ### Nature transformation for cyclical variables\n",
    "\n",
    "        # day of week\n",
    "        df5['day_of_week_sin'] = df5['day_of_week'].apply(lambda x : np.sin(x*(2.*np.pi/7)))\n",
    "        df5['day_of_week_cos'] = df5['day_of_week'].apply(lambda x : np.cos(x*(2.*np.pi/7)))\n",
    "\n",
    "        # month\n",
    "        df5['month_sin'] = df5['month'].apply(lambda x : np.sin(x*(2.*np.pi/12)))\n",
    "        df5['month_cos'] = df5['month'].apply(lambda x : np.cos(x*(2.*np.pi/12)))\n",
    "\n",
    "        # day\n",
    "        df5['day_sin'] = df5['day'].apply(lambda x : np.sin(x*(2.*np.pi/30)))\n",
    "        df5['day_cos'] = df5['day'].apply(lambda x : np.cos(x*(2.*np.pi/30)))\n",
    "\n",
    "        # week of year\n",
    "        df5['week_of_year_sin'] = df5['week_of_year'].apply(lambda x : np.sin(x*(2.*np.pi/52)))\n",
    "        df5['week_of_year_cos'] = df5['week_of_year'].apply(lambda x : np.cos(x*(2.*np.pi/52)))\n",
    "        \n",
    "        cols_selected_boruta = ['store',\n",
    "                            'promo',\n",
    "                            'store_type',\n",
    "                            'assortment',\n",
    "                            'promo2',\n",
    "                            'competition_time_month',\n",
    "                            'promo_time_week',\n",
    "                            'competition_str',\n",
    "                            'day_of_week_sin',\n",
    "                            'day_of_week_cos',\n",
    "                            'month_cos',\n",
    "                            'day_sin',\n",
    "                            'day_cos',\n",
    "                            'week_of_year_cos'\n",
    "                           ]\n",
    "        \n",
    "        return df5[cols_selected_boruta]\n",
    "\n",
    "    def get_prediction(self, model, original_data, test_data):\n",
    "        #prediction\n",
    "        pred = model.predict(test_data)\n",
    "        \n",
    "        # join pred with original data\n",
    "        original_data['prediction'] = np.empm1(pred)\n",
    "                  \n",
    "        return original_data.to_json(orient='records', date_format = 'iso')\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c403e7",
   "metadata": {},
   "source": [
    "## API Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "446a9726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from flask import Flask, request, Response\n",
    "from rossmann.Rossmann import Rossmann\n",
    "\n",
    "#loading model\n",
    "model = pickle.load(open(r'C:\\Users\\06564176686\\repos\\Store-Sales-Prediction\\model\\model_rossmann.pkl', 'rb'))\n",
    "\n",
    "# initializa API\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/rossmann/predict', methods = ['POST'])\n",
    "def rossmann_predict():\n",
    "    test_json = request.get_json()\n",
    "    \n",
    "    if test_json:\n",
    "        # unique example\n",
    "        if isinstance(test_json, dict):\n",
    "            test_raw = pd.DataFrame(test_json, index=[0])\n",
    "        # multiple examples\n",
    "        else:\n",
    "             test_raw = pd.DataFrame(test_json, columns = test_json[0].keys())\n",
    "                \n",
    "        # Instantiate Rossmann class\n",
    "        pipeline = Rossmann()\n",
    "                \n",
    "        # data cleaning\n",
    "        df1 = pipeline.data_cleaning(test_raw)\n",
    "        \n",
    "        # feature engineering\n",
    "        df2 = pipeline.feature_engineering(df1)\n",
    "            \n",
    "        # data preparation\n",
    "        df3 = pipeline.datapreparation(df2)\n",
    "        \n",
    "        # prediction\n",
    "        df_response = pipeline.get_prediction(model, test_raw, df3)\n",
    "        \n",
    "        return df_response\n",
    "        \n",
    "    else:\n",
    "        return Response('{}', status=200, mimetype='aookication/json')\n",
    "\n",
    "if __name__ == 'main':\n",
    "    app.run('0.0.0.0')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91589dbc",
   "metadata": {},
   "source": [
    "## API Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9d858cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# loading test dataset\n",
    "df10 = pd.read_csv('data/test.csv', low_memory=False)\n",
    "\n",
    "df_test = pd.merge(df10, df_store_raw, how='left', on='Store')\n",
    "\n",
    "# choose store for prediction\n",
    "df_test = df_test[df_test['Store']==34]\n",
    "\n",
    "# remove closed days\n",
    "df_test = df_test[df_test['Open']!=0]\n",
    "df_test = df_test[~df_test['Open'].isnull()]\n",
    "df_test = df_test.drop('Id', axis=1)\n",
    "\n",
    "# convert DataFrame to json\n",
    "data = json.dumps( df_test.to_dict( orient = 'records' ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9118d523",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='0.0.0.0', port=5000): Max retries exceeded with url: /rossmann/predict (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000026A803B1580>: Failed to establish a new connection: [WinError 10049] O endereço solicitado não é válido no contexto'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             conn = connection.create_connection(\n\u001b[0m\u001b[0;32m    170\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 10049] O endereço solicitado não é válido no contexto",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    393\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                 \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"User-Agent\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_default_user_agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1256\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1257\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1302\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1303\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1251\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1012\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    953\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSocketError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             raise NewConnectionError(\n\u001b[0m\u001b[0;32m    182\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x0000026A803B1580>: Failed to establish a new connection: [WinError 10049] O endereço solicitado não é válido no contexto",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m             retries = retries.increment(\n\u001b[0m\u001b[0;32m    756\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='0.0.0.0', port=5000): Max retries exceeded with url: /rossmann/predict (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000026A803B1580>: Failed to establish a new connection: [WinError 10049] O endereço solicitado não é válido no contexto'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\065641~1\\AppData\\Local\\Temp/ipykernel_13984/3525696142.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Status Code {}.format(r.status_code)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \"\"\"\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'post'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    540\u001b[0m         }\n\u001b[0;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DataScienceEmProducao\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPConnectionPool(host='0.0.0.0', port=5000): Max retries exceeded with url: /rossmann/predict (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000026A803B1580>: Failed to establish a new connection: [WinError 10049] O endereço solicitado não é válido no contexto'))"
     ]
    }
   ],
   "source": [
    "# API Call\n",
    "url = 'http://0.0.0.0:5000/rossmann/predict'\n",
    "header = {'Content-type': 'application/json'}\n",
    "data = data\n",
    "\n",
    "r = requests.post( url, data=data, headers=header)\n",
    "print(\"Status Code {}.format(r.status_code)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9659ab5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\065641~1\\AppData\\Local\\Temp/ipykernel_13984/665377493.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0md1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "d1 = pd.DataFrame(r.json(), columns = r.json()[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8773d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
